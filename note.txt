1. просто загружаем датасет и берём из него сочетания признаков и следствие из них

2. чтобы избежать переобучения — разбиваем набор на две части, на train применяем классификатор и лучшей модель применяем к test

3. в gridSearch меняя гиперпараметры, оцениваем f-меру и сравниваем сначала с baseLine, потом между собой

4. folds (https://scikit-learn.org/stable/modules/cross_validation.html)
В базовом подходе, называемом k-кратным CV, обучающий набор разбивается на k меньших наборов. Для каждого набора исполняется следующее:
Модель обучается с использованием k-1 складок в качестве обучающих данных; Полученная модель проверяется на оставшейся части данных (т.е. она используется в качестве тестового набора для вычисления показателя производительности, такого как точность).
